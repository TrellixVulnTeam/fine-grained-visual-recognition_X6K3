{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amber-amount",
   "metadata": {
    "id": "prerequisite-removal"
   },
   "source": [
    "# 02 - Adjusting Predictions Using Metadata Priors for All Networks (DF20M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699e6deb-70c9-495d-ae79-f5a03e697aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earlier-liechtenstein",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olympic-table",
    "outputId": "517462e8-03e7-4bc8-df39-76bc7ef6d105"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.core import training, metrics\n",
    "from src.special import calibration, proba_model\n",
    "from src.utils import io\n",
    "\n",
    "PREDICTIONS_DIR = 'predictions/'\n",
    "DATA_DIR = 'data/danish_fungi_dataset/'\n",
    "\n",
    "PRED_FILES = {\n",
    "    'EfficientNet-B0': 'fungi_mini_efficientnet_b0_pred.npy',\n",
    "    'ViT-Base-224': 'fungi_mini_vit_base_224_pred.npy',\n",
    "\n",
    "    'EfficientNet-B4': 'fungi_mini_efficientnet_b4_pred.npy',\n",
    "    'NoisyStudent-B4': 'fungi_mini_efficientnet_b4_ns_pred.npy',\n",
    "    'EfficientNetV2-S': 'fungi_mini_efficientnetv2_s_pred.npy',\n",
    "\n",
    "    'ViT-Base-384': 'fungi_mini_vit_base_384_pred.npy',\n",
    "    'DeiT-Base-384': 'fungi_mini_deit_base_384_pred.npy',\n",
    "    'BEiT-Base-384': 'fungi_mini_beit_base_384_pred.npy',\n",
    "\n",
    "    'ViT-Large-384': 'fungi_mini_vit_large_384_pred.npy'}\n",
    "TARG_FILE = 'fungi_mini_targ.npy'\n",
    "\n",
    "M = 0.1  # m-estimates parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-neighbor",
   "metadata": {
    "id": "express-soldier"
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mysterious-enforcement",
   "metadata": {
    "id": "dangerous-marijuana"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No classes: 182\n",
      "Train set length: 32,753\n",
      "Validation set length: 3,640\n"
     ]
    }
   ],
   "source": [
    "# load metadata\n",
    "train_df = pd.read_csv(DATA_DIR + 'DF20M-train_metadata_PROD.csv')\n",
    "valid_df = pd.read_csv(DATA_DIR + 'DF20M-public_test_metadata_PROD.csv')\n",
    "\n",
    "classes = np.unique(train_df['scientificName'])\n",
    "no_classes = len(classes)\n",
    "assert no_classes == len(np.unique(valid_df['scientificName']))\n",
    "print(f'No classes: {no_classes}')\n",
    "print(f'Train set length: {len(train_df):,d}')\n",
    "print(f'Validation set length: {len(valid_df):,d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5c65b4-2346-45dc-bff7-ae74d8be8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 17,221\n",
      "Validation set length: 3,397\n"
     ]
    }
   ],
   "source": [
    "train_df['observation_id'] = train_df['ImageUniqueID'].str.split('-').str[0]\n",
    "valid_df['observation_id'] = valid_df['ImageUniqueID'].str.split('-').str[0]\n",
    "\n",
    "cond = ~valid_df.duplicated('observation_id').values\n",
    "# cond = ~valid_df.duplicated('observation_id').values & ~valid_df['observation_id'].isin(train_df['observation_id'])\n",
    "\n",
    "train_df = train_df.drop_duplicates('observation_id')\n",
    "train_df = train_df[~train_df['observation_id'].isin(valid_df['observation_id'])]\n",
    "valid_df = valid_df.drop_duplicates('observation_id')\n",
    "# valid_df = valid_df[~valid_df['observation_id'].isin(train_df['observation_id'])]\n",
    "print(f'Train set length: {len(train_df):,d}')\n",
    "print(f'Validation set length: {len(valid_df):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db4b6a-76e0-4708-90e0-6fa0c777490f",
   "metadata": {},
   "source": [
    "## Compute Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7eaaf0-9391-4a46-8256-faa151e497fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(PREDICTIONS_DIR):\n",
    "    os.mkdir(PREDICTIONS_DIR)\n",
    "\n",
    "# compute predictions\n",
    "if not all([os.path.isfile(PREDICTIONS_DIR + x) for x in PRED_FILES.values()]):\n",
    "    !sh test_fungi.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ee15c-25da-488a-a962-a57574b09a17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33224cc-cda6-45a9-bd3a-a44cf599fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:23<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def softmax(x, temperature=None):\n",
    "    if temperature is not None:\n",
    "        x = x / temperature\n",
    "    e = np.exp(x - x.max())  # X.max() makes function exp more stable\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "# load target file\n",
    "targ = np.load(PREDICTIONS_DIR + TARG_FILE)\n",
    "targ = targ[cond]\n",
    "\n",
    "# load prediction file of each model and compute scores\n",
    "logits_dict = {}\n",
    "preds_dict = {}\n",
    "for model_name, pred_file in tqdm(PRED_FILES.items()):\n",
    "    # load prediction file\n",
    "    logits = np.load(PREDICTIONS_DIR + pred_file)\n",
    "    logits = logits[cond]\n",
    "\n",
    "    # calibrate predictions\n",
    "    temperature = calibration.tune_temperature(\n",
    "        logits=logits, targs=targ, verbose=False)\n",
    "\n",
    "    # apply softmax with temperature\n",
    "    pred = softmax(logits, temperature=temperature)\n",
    "    preds_dict[model_name] = pred\n",
    "    logits_dict[model_name] = logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a2751-fa3f-474f-8d2f-124594e8acf8",
   "metadata": {},
   "source": [
    "## Estimate Metadata-Target Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2cabaf-73c9-48ab-bd50-38c0c0380dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class distributions\n",
    "class_priors = proba_model.estimate_relative_freq(train_df['scientificName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73a6a3-c75a-489c-bd75-e4498bcabc55",
   "metadata": {},
   "source": [
    "### Habitat, Substrate, Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc13aaf-0096-4966-8ee9-b06308c7af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_metadata_probability(train_df, valid_df, col, m=1):\n",
    "    hist = proba_model.HistogramClassifier(m=m)\n",
    "    hist.fit(train_df[col], train_df['scientificName'])\n",
    "    metadata_pred = hist.predict_proba(valid_df[col])\n",
    "    return metadata_pred\n",
    "\n",
    "# create metadata posteriors\n",
    "metadata_cols = ['Habitat', 'Substrate', 'month']\n",
    "metadata_preds_dict = {\n",
    "    col: predict_metadata_probability(train_df, valid_df, col, m=M)\n",
    "    for col in metadata_cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f1e41-1a16-4ff2-8503-15d32d3d5f57",
   "metadata": {},
   "source": [
    "### GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c65ef7-50b6-42a2-9891-7e6e0d93a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gps_probability(train_df, valid_df, bandwidth=0.2, kernel='exponential', metric='haversine'):\n",
    "    kde = proba_model.KDEClassifier(bandwidth=bandwidth, kernel=kernel, metric=metric)\n",
    "    kde.fit(train_df[['Latitude', 'Longitude']], train_df['scientificName'])\n",
    "    gps_pred = kde.predict_proba(valid_df[['Latitude', 'Longitude']])\n",
    "\n",
    "    return gps_pred\n",
    "\n",
    "\n",
    "metadata_preds_dict['GPS'] = predict_gps_probability(\n",
    "    train_df, valid_df, bandwidth=0.2, kernel='exponential', metric='haversine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cfaab-518a-4870-8c40-c222c9292d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b50c70-9a72-4f3f-bf37-a83df253e4f2",
   "metadata": {},
   "source": [
    "## Combine Predictions with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0638a91-b2f6-4806-8650-9e0d3cdabb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:26<00:00,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# adjust predictions with metadata and compute scores\n",
    "scores_dict = {}\n",
    "adj_scores_dict = {}\n",
    "for model_name, pred in tqdm(preds_dict.items()):\n",
    "    logits = logits_dict[model_name]\n",
    "\n",
    "    # tune temperature for image and metadata predictions\n",
    "    combined_preds = np.ones(pred.shape)\n",
    "    for k in metadata_preds_dict.keys():\n",
    "        metadata_pred = metadata_preds_dict[k]\n",
    "        combined_preds *= metadata_pred / class_priors\n",
    "    temperature = calibration.tune_temperature(\n",
    "            logits=logits, targs=targ, other_preds=combined_preds, verbose=False)\n",
    "\n",
    "    # adjust predictions using metadata\n",
    "    pred_adj = softmax(logits, temperature) * combined_preds\n",
    "\n",
    "    # compute scores\n",
    "    scores_dict[model_name] = training.classification_scores(pred, targ)\n",
    "    adj_scores_dict[model_name] = training.classification_scores(pred_adj, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a25824-5c9b-4a98-9888-6c4fe43102d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19d72e60-a145-41f1-be4f-e93ae2b0387d",
   "metadata": {},
   "source": [
    "## Evaluate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea62b651-adec-49d2-81b0-df5734ad7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame.from_dict(scores_dict, orient='index')\n",
    "scores_df.columns = pd.MultiIndex.from_product([scores_df.columns, ['Original']])\n",
    "adj_scores_df = pd.DataFrame.from_dict(adj_scores_dict, orient='index')\n",
    "adj_scores_df.columns = pd.MultiIndex.from_product([adj_scores_df.columns, ['Adjusted']])\n",
    "\n",
    "eval_df = pd.concat([scores_df, adj_scores_df], axis=1)\n",
    "for met in ['accuracy', 'top_3', 'f1_score']:\n",
    "    eval_df[met, 'Diff'] = eval_df[met, 'Adjusted'] - eval_df[met, 'Original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95500261-1e2a-4be3-9b42-7a2836089b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">top_3</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Original</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Original</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EfficientNet-B0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>67.7</td>\n",
       "      <td>+4.8</td>\n",
       "      <td>81.4</td>\n",
       "      <td>85.3</td>\n",
       "      <td>+3.9</td>\n",
       "      <td>52.2</td>\n",
       "      <td>59.2</td>\n",
       "      <td>+7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-Base-224</th>\n",
       "      <td>68.7</td>\n",
       "      <td>71.5</td>\n",
       "      <td>+2.8</td>\n",
       "      <td>85.6</td>\n",
       "      <td>87.7</td>\n",
       "      <td>+2.1</td>\n",
       "      <td>58.4</td>\n",
       "      <td>61.7</td>\n",
       "      <td>+3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientNet-B4</th>\n",
       "      <td>68.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>+3.8</td>\n",
       "      <td>85.2</td>\n",
       "      <td>88.3</td>\n",
       "      <td>+3.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>62.2</td>\n",
       "      <td>+4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoisyStudent-B4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>73.6</td>\n",
       "      <td>+3.6</td>\n",
       "      <td>86.9</td>\n",
       "      <td>88.6</td>\n",
       "      <td>+1.7</td>\n",
       "      <td>61.3</td>\n",
       "      <td>64.9</td>\n",
       "      <td>+3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientNetV2-S</th>\n",
       "      <td>69.8</td>\n",
       "      <td>73.0</td>\n",
       "      <td>+3.2</td>\n",
       "      <td>86.4</td>\n",
       "      <td>88.7</td>\n",
       "      <td>+2.3</td>\n",
       "      <td>60.7</td>\n",
       "      <td>65.4</td>\n",
       "      <td>+4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-Base-384</th>\n",
       "      <td>75.2</td>\n",
       "      <td>76.9</td>\n",
       "      <td>+1.7</td>\n",
       "      <td>88.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>+1.2</td>\n",
       "      <td>65.8</td>\n",
       "      <td>67.9</td>\n",
       "      <td>+2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeiT-Base-384</th>\n",
       "      <td>73.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>+2.2</td>\n",
       "      <td>87.9</td>\n",
       "      <td>89.8</td>\n",
       "      <td>+1.9</td>\n",
       "      <td>63.4</td>\n",
       "      <td>66.6</td>\n",
       "      <td>+3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEiT-Base-384</th>\n",
       "      <td>73.6</td>\n",
       "      <td>76.9</td>\n",
       "      <td>+3.3</td>\n",
       "      <td>88.4</td>\n",
       "      <td>90.7</td>\n",
       "      <td>+2.3</td>\n",
       "      <td>64.2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>+4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-Large-384</th>\n",
       "      <td>76.0</td>\n",
       "      <td>78.3</td>\n",
       "      <td>+2.4</td>\n",
       "      <td>89.7</td>\n",
       "      <td>90.6</td>\n",
       "      <td>+0.9</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>+3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy                   top_3                f1_score  \\\n",
       "                 Original Adjusted  Diff Original Adjusted  Diff Original   \n",
       "EfficientNet-B0      63.0     67.7  +4.8     81.4     85.3  +3.9     52.2   \n",
       "ViT-Base-224         68.7     71.5  +2.8     85.6     87.7  +2.1     58.4   \n",
       "EfficientNet-B4      68.0     71.8  +3.8     85.2     88.3  +3.1     58.0   \n",
       "NoisyStudent-B4      70.0     73.6  +3.6     86.9     88.6  +1.7     61.3   \n",
       "EfficientNetV2-S     69.8     73.0  +3.2     86.4     88.7  +2.3     60.7   \n",
       "ViT-Base-384         75.2     76.9  +1.7     88.8     90.0  +1.2     65.8   \n",
       "DeiT-Base-384        73.6     75.8  +2.2     87.9     89.8  +1.9     63.4   \n",
       "BEiT-Base-384        73.6     76.9  +3.3     88.4     90.7  +2.3     64.2   \n",
       "ViT-Large-384        76.0     78.3  +2.4     89.7     90.6  +0.9     66.0   \n",
       "\n",
       "                                 \n",
       "                 Adjusted  Diff  \n",
       "EfficientNet-B0      59.2  +7.1  \n",
       "ViT-Base-224         61.7  +3.3  \n",
       "EfficientNet-B4      62.2  +4.1  \n",
       "NoisyStudent-B4      64.9  +3.7  \n",
       "EfficientNetV2-S     65.4  +4.7  \n",
       "ViT-Base-384         67.9  +2.1  \n",
       "DeiT-Base-384        66.6  +3.3  \n",
       "BEiT-Base-384        69.0  +4.8  \n",
       "ViT-Large-384        69.0  +3.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = eval_df[['accuracy', 'top_3', 'f1_score']].round(3) * 100\n",
    "for met in ['accuracy', 'top_3', 'f1_score']:\n",
    "    _df[met, 'Diff'] = '+' + _df[met, 'Diff'].round(1).fillna('').astype(str).replace('+', np.nan)\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793fe76-0675-46e2-9cf8-5bda865e8cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "05b_country_f1_score_on_CLEF2021.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
