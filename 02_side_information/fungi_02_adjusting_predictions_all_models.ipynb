{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amber-amount",
   "metadata": {
    "id": "prerequisite-removal"
   },
   "source": [
    "# 02 - Adjusting Predictions Using Metadata Priors for All Networks (DF20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699e6deb-70c9-495d-ae79-f5a03e697aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earlier-liechtenstein",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olympic-table",
    "outputId": "517462e8-03e7-4bc8-df39-76bc7ef6d105"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.core import training, metrics\n",
    "from src.special import calibration, proba_model\n",
    "from src.utils import io\n",
    "\n",
    "PREDICTIONS_DIR = 'predictions/'\n",
    "DATA_DIR = 'data/danish_fungi_dataset/'\n",
    "\n",
    "PRED_FILES = {\n",
    "    'EfficientNet-B0': 'fungi_full_efficientnet_b0_pred.npy',\n",
    "    'ViT-Base-224': 'fungi_full_vit_base_224_pred.npy',\n",
    "\n",
    "    'EfficientNet-B4': 'fungi_full_efficientnet_b4_pred.npy',\n",
    "    'NoisyStudent-B4': 'fungi_full_efficientnet_b4_ns_pred.npy',\n",
    "    'EfficientNetV2-S': 'fungi_full_efficientnetv2_s_pred.npy',\n",
    "\n",
    "    'ViT-Base-384': 'fungi_full_vit_base_384_pred.npy',\n",
    "    'DeiT-Base-384': 'fungi_full_deit_base_384_pred.npy',\n",
    "    'BEiT-Base-384': 'fungi_full_beit_base_384_pred.npy',\n",
    "\n",
    "    'ViT-Large-384': 'fungi_full_vit_large_384_pred.npy'}\n",
    "TARG_FILE = 'fungi_full_targ.npy'\n",
    "\n",
    "M = 0.1  # m-estimates parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-neighbor",
   "metadata": {
    "id": "express-soldier"
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mysterious-enforcement",
   "metadata": {
    "id": "dangerous-marijuana"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No classes: 1604\n",
      "Train set length: 266,344\n",
      "Validation set length: 29,594\n"
     ]
    }
   ],
   "source": [
    "# load metadata\n",
    "train_df = pd.read_csv(DATA_DIR + 'DF20-train_metadata_PROD.csv')\n",
    "valid_df = pd.read_csv(DATA_DIR + 'DF20-public_test_metadata_PROD.csv')\n",
    "\n",
    "classes = np.unique(train_df['scientificName'])\n",
    "no_classes = len(classes)\n",
    "assert no_classes == len(np.unique(valid_df['scientificName']))\n",
    "print(f'No classes: {no_classes}')\n",
    "print(f'Train set length: {len(train_df):,d}')\n",
    "print(f'Validation set length: {len(valid_df):,d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5c65b4-2346-45dc-bff7-ae74d8be8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 149,356\n",
      "Validation set length: 27,814\n"
     ]
    }
   ],
   "source": [
    "train_df['observation_id'] = train_df['ImageUniqueID'].str.split('-').str[0]\n",
    "valid_df['observation_id'] = valid_df['ImageUniqueID'].str.split('-').str[0]\n",
    "\n",
    "cond = ~valid_df.duplicated('observation_id').values\n",
    "# cond = ~valid_df.duplicated('observation_id').values & ~valid_df['observation_id'].isin(train_df['observation_id'])\n",
    "\n",
    "train_df = train_df.drop_duplicates('observation_id')\n",
    "train_df = train_df[~train_df['observation_id'].isin(valid_df['observation_id'])]\n",
    "valid_df = valid_df.drop_duplicates('observation_id')\n",
    "# valid_df = valid_df[~valid_df['observation_id'].isin(train_df['observation_id'])]\n",
    "print(f'Train set length: {len(train_df):,d}')\n",
    "print(f'Validation set length: {len(valid_df):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db4b6a-76e0-4708-90e0-6fa0c777490f",
   "metadata": {},
   "source": [
    "## Compute Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7eaaf0-9391-4a46-8256-faa151e497fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(PREDICTIONS_DIR):\n",
    "    os.mkdir(PREDICTIONS_DIR)\n",
    "\n",
    "# compute predictions\n",
    "if not all([os.path.isfile(PREDICTIONS_DIR + x) for x in PRED_FILES.values()]):\n",
    "    !sh test_fungi.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ee15c-25da-488a-a962-a57574b09a17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33224cc-cda6-45a9-bd3a-a44cf599fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [04:00<00:00, 26.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def softmax(x, temperature=None):\n",
    "    if temperature is not None:\n",
    "        x = x / temperature\n",
    "    e = np.exp(x - x.max())  # X.max() makes function exp more stable\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "# load target file\n",
    "targ = np.load(PREDICTIONS_DIR + TARG_FILE)\n",
    "targ = targ[cond]\n",
    "\n",
    "# load prediction file of each model and compute scores\n",
    "logits_dict = {}\n",
    "preds_dict = {}\n",
    "for model_name, pred_file in tqdm(PRED_FILES.items()):\n",
    "    # load prediction file\n",
    "    logits = np.load(PREDICTIONS_DIR + pred_file)\n",
    "    logits = logits[cond]\n",
    "\n",
    "    # calibrate predictions\n",
    "    temperature = calibration.tune_temperature(\n",
    "        logits=logits, targs=targ, verbose=False)\n",
    "\n",
    "    # apply softmax with temperature\n",
    "    pred = softmax(logits, temperature=temperature)\n",
    "    preds_dict[model_name] = pred\n",
    "    logits_dict[model_name] = logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a2751-fa3f-474f-8d2f-124594e8acf8",
   "metadata": {},
   "source": [
    "## Estimate Metadata-Target Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2cabaf-73c9-48ab-bd50-38c0c0380dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class distributions\n",
    "class_priors = proba_model.estimate_relative_freq(train_df['scientificName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3e9be-1d2b-4921-8944-8ec9d6943939",
   "metadata": {},
   "source": [
    "### Habitat, Substrate, Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4077dace-60c5-46fd-8441-168837a2f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_metadata_probability(train_df, valid_df, col, m=1):\n",
    "    hist = proba_model.HistogramClassifier(m=m)\n",
    "    hist.fit(train_df[col], train_df['scientificName'])\n",
    "    metadata_pred = hist.predict_proba(valid_df[col])\n",
    "    return metadata_pred\n",
    "\n",
    "# create metadata posteriors\n",
    "metadata_cols = ['Habitat', 'Substrate', 'month']\n",
    "metadata_preds_dict = {\n",
    "    col: predict_metadata_probability(train_df, valid_df, col, m=M)\n",
    "    for col in metadata_cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71966b04-cc51-4206-b7c3-609e4e81cd72",
   "metadata": {},
   "source": [
    "### GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5be7a8-b7d1-4c10-ac18-1642977c9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gps_probability(train_df, valid_df, bandwidth=0.2, kernel='exponential', metric='haversine'):\n",
    "    kde = proba_model.KDEClassifier(bandwidth=bandwidth, kernel=kernel, metric=metric)\n",
    "    kde.fit(train_df[['Latitude', 'Longitude']], train_df['scientificName'])\n",
    "    gps_pred = kde.predict_proba(valid_df[['Latitude', 'Longitude']])\n",
    "\n",
    "    return gps_pred\n",
    "\n",
    "\n",
    "metadata_preds_dict['GPS'] = predict_gps_probability(\n",
    "    train_df, valid_df, bandwidth=0.2, kernel='exponential', metric='haversine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cfaab-518a-4870-8c40-c222c9292d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b50c70-9a72-4f3f-bf37-a83df253e4f2",
   "metadata": {},
   "source": [
    "## Combine Predictions with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0638a91-b2f6-4806-8650-9e0d3cdabb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:42<00:00, 24.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# adjust predictions with metadata and compute scores\n",
    "scores_dict = {}\n",
    "adj_scores_dict = {}\n",
    "for model_name, pred in tqdm(preds_dict.items()):\n",
    "    logits = logits_dict[model_name]\n",
    "\n",
    "    # tune temperature for image and metadata predictions\n",
    "    combined_preds = np.ones(pred.shape)\n",
    "    for k in metadata_preds_dict.keys():\n",
    "        metadata_pred = metadata_preds_dict[k]\n",
    "        combined_preds *= metadata_pred / class_priors\n",
    "    temperature = calibration.tune_temperature(\n",
    "            logits=logits, targs=targ, other_preds=combined_preds, verbose=False)\n",
    "\n",
    "    # adjust predictions using metadata\n",
    "    pred_adj = softmax(logits, temperature) * combined_preds\n",
    "\n",
    "    # compute scores\n",
    "    scores_dict[model_name] = training.classification_scores(pred, targ)\n",
    "    adj_scores_dict[model_name] = training.classification_scores(pred_adj, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a25824-5c9b-4a98-9888-6c4fe43102d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19d72e60-a145-41f1-be4f-e93ae2b0387d",
   "metadata": {},
   "source": [
    "## Evaluate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea62b651-adec-49d2-81b0-df5734ad7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame.from_dict(scores_dict, orient='index')\n",
    "scores_df.columns = pd.MultiIndex.from_product([scores_df.columns, ['Original']])\n",
    "adj_scores_df = pd.DataFrame.from_dict(adj_scores_dict, orient='index')\n",
    "adj_scores_df.columns = pd.MultiIndex.from_product([adj_scores_df.columns, ['Adjusted']])\n",
    "\n",
    "eval_df = pd.concat([scores_df, adj_scores_df], axis=1)\n",
    "for met in ['accuracy', 'top_3', 'f1_score']:\n",
    "    eval_df[met, 'Diff'] = eval_df[met, 'Adjusted'] - eval_df[met, 'Original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba28132-b555-4d6e-85c7-2013c5c8ca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">top_3</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Original</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Original</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EfficientNet-B0</th>\n",
       "      <td>67.1</td>\n",
       "      <td>70.7</td>\n",
       "      <td>+3.6</td>\n",
       "      <td>83.4</td>\n",
       "      <td>86.2</td>\n",
       "      <td>+2.8</td>\n",
       "      <td>59.5</td>\n",
       "      <td>64.6</td>\n",
       "      <td>+5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-Base-224</th>\n",
       "      <td>73.7</td>\n",
       "      <td>76.4</td>\n",
       "      <td>+2.6</td>\n",
       "      <td>87.3</td>\n",
       "      <td>89.1</td>\n",
       "      <td>+1.8</td>\n",
       "      <td>66.2</td>\n",
       "      <td>69.1</td>\n",
       "      <td>+2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientNet-B4</th>\n",
       "      <td>74.6</td>\n",
       "      <td>77.1</td>\n",
       "      <td>+2.5</td>\n",
       "      <td>88.4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>+1.6</td>\n",
       "      <td>67.7</td>\n",
       "      <td>71.0</td>\n",
       "      <td>+3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoisyStudent-B4</th>\n",
       "      <td>75.5</td>\n",
       "      <td>78.6</td>\n",
       "      <td>+3.1</td>\n",
       "      <td>89.1</td>\n",
       "      <td>91.1</td>\n",
       "      <td>+1.9</td>\n",
       "      <td>68.6</td>\n",
       "      <td>72.7</td>\n",
       "      <td>+4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientNetV2-S</th>\n",
       "      <td>76.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>+2.3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.6</td>\n",
       "      <td>+1.6</td>\n",
       "      <td>69.2</td>\n",
       "      <td>72.1</td>\n",
       "      <td>+2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-Base-384</th>\n",
       "      <td>79.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>+1.5</td>\n",
       "      <td>90.8</td>\n",
       "      <td>91.6</td>\n",
       "      <td>+0.8</td>\n",
       "      <td>71.9</td>\n",
       "      <td>73.1</td>\n",
       "      <td>+1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeiT-Base-384</th>\n",
       "      <td>78.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>+1.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>91.2</td>\n",
       "      <td>+0.9</td>\n",
       "      <td>70.9</td>\n",
       "      <td>72.5</td>\n",
       "      <td>+1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEiT-Base-384</th>\n",
       "      <td>77.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>+2.1</td>\n",
       "      <td>89.9</td>\n",
       "      <td>91.3</td>\n",
       "      <td>+1.4</td>\n",
       "      <td>69.6</td>\n",
       "      <td>72.1</td>\n",
       "      <td>+2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-Large-384</th>\n",
       "      <td>81.0</td>\n",
       "      <td>81.9</td>\n",
       "      <td>+0.9</td>\n",
       "      <td>92.1</td>\n",
       "      <td>92.1</td>\n",
       "      <td>+0.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.8</td>\n",
       "      <td>+0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy                   top_3                f1_score  \\\n",
       "                 Original Adjusted  Diff Original Adjusted  Diff Original   \n",
       "EfficientNet-B0      67.1     70.7  +3.6     83.4     86.2  +2.8     59.5   \n",
       "ViT-Base-224         73.7     76.4  +2.6     87.3     89.1  +1.8     66.2   \n",
       "EfficientNet-B4      74.6     77.1  +2.5     88.4     90.0  +1.6     67.7   \n",
       "NoisyStudent-B4      75.5     78.6  +3.1     89.1     91.1  +1.9     68.6   \n",
       "EfficientNetV2-S     76.0     78.2  +2.3     89.0     90.6  +1.6     69.2   \n",
       "ViT-Base-384         79.0     80.6  +1.5     90.8     91.6  +0.8     71.9   \n",
       "DeiT-Base-384        78.3     80.0  +1.7     90.3     91.2  +0.9     70.9   \n",
       "BEiT-Base-384        77.5     79.5  +2.1     89.9     91.3  +1.4     69.6   \n",
       "ViT-Large-384        81.0     81.9  +0.9     92.1     92.1  +0.1     74.6   \n",
       "\n",
       "                                 \n",
       "                 Adjusted  Diff  \n",
       "EfficientNet-B0      64.6  +5.0  \n",
       "ViT-Base-224         69.1  +2.9  \n",
       "EfficientNet-B4      71.0  +3.3  \n",
       "NoisyStudent-B4      72.7  +4.0  \n",
       "EfficientNetV2-S     72.1  +2.9  \n",
       "ViT-Base-384         73.1  +1.2  \n",
       "DeiT-Base-384        72.5  +1.6  \n",
       "BEiT-Base-384        72.1  +2.6  \n",
       "ViT-Large-384        74.8  +0.2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = eval_df[['accuracy', 'top_3', 'f1_score']].round(3) * 100\n",
    "for met in ['accuracy', 'top_3', 'f1_score']:\n",
    "    _df[met, 'Diff'] = '+' + _df[met, 'Diff'].round(1).fillna('').astype(str).replace('+', np.nan)\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793fe76-0675-46e2-9cf8-5bda865e8cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "05b_country_f1_score_on_CLEF2021.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
