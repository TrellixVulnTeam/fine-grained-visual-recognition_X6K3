{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Danish Fungi - Localize Saliency Regions for all Images (DF20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.core import data, training, models, metrics\n",
    "from src.special import saliency\n",
    "from src.utils import nb_setup, progress_log, visualization as viz\n",
    "\n",
    "BBOX_DATA_DIR = '03_informed_augmentation/data_fungi/'\n",
    "DATA_DIR = 'data/danish_fungi_dataset/'\n",
    "TRAIN_SET_DIR = 'train_resized'\n",
    "\n",
    "MODEL_ARCH = 'efficientnet_b0'\n",
    "MODEL_NAME = 'baselines/df2020_efficientnet_b0_ce_11-28-2021_11-38-24'\n",
    "\n",
    "OUTPUT_FILE = 'DF_bbox_annotations.csv'\n",
    "\n",
    "nb_setup.init()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No classes: 1604\n",
      "Train set length: 266,344\n",
      "Validation set length: 29,594\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_DIR + 'DF20-train_metadata_PROD.csv')\n",
    "valid_df = pd.read_csv(DATA_DIR + 'DF20-public_test_metadata_PROD.csv')\n",
    "\n",
    "classes = np.unique(train_df['scientificName'])\n",
    "no_classes = len(classes)\n",
    "assert no_classes == len(np.unique(valid_df['scientificName']))\n",
    "print(f'No classes: {no_classes}')\n",
    "print(f'Train set length: {len(train_df):,d}')\n",
    "print(f'Validation set length: {len(valid_df):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = models.get_model(MODEL_ARCH, no_classes, pretrained=True)\n",
    "training.load_model(model, MODEL_NAME, path=DATA_DIR + 'models')\n",
    "assert np.all([param.requires_grad for param in model.parameters()])\n",
    "\n",
    "model_config = model.pretrained_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transforms\n",
    "_, valid_tfms = data.get_transforms(\n",
    "    size=model_config['input_size'], mean=model_config['image_mean'],\n",
    "    std=model_config['image_std'])\n",
    "\n",
    "# create dataset\n",
    "dataset = data.ImageDataset(\n",
    "    pd.concat([train_df, valid_df], axis=0),\n",
    "    img_path_col='image_path', label_col='scientificName',\n",
    "    path=DATA_DIR + TRAIN_SET_DIR, transforms=valid_tfms,\n",
    "    labels=classes)\n",
    "\n",
    "# dataset.show_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bounding Box Annotation for the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bbox(model, img, label, device=None):\n",
    "    # create saliency map\n",
    "    saliency_map = saliency.get_saliency_map(model, img, label=label, device=device)\n",
    "\n",
    "    # get bounding box covering highest intensities\n",
    "    bbox, saliency_map_cleaned = saliency.get_bounding_box(\n",
    "        saliency_map, bin_percentile=95, clust_pixel_th=10)\n",
    "    _, h, w = img.shape\n",
    "    bbox = data.BBox(*bbox).normalize(h, w)  # normalize bbox\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize example\n",
    "# fig, axs = viz.create_fig(ncols=4, nrows=4, colsize=3, rowsize=3)\n",
    "# for i, ax in enumerate(axs):\n",
    "#     img, label = dataset[i]\n",
    "#     bbox = find_bbox(model, img, label, device=device)\n",
    "\n",
    "#     bbox = bbox.denormalize(224, 224)\n",
    "#     viz.imshow(img, bbox=bbox, title=f'{label}', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# load already finished records\n",
    "score_names = None\n",
    "completed_ids = []\n",
    "if os.path.isfile(BBOX_DATA_DIR + OUTPUT_FILE):\n",
    "    df = pd.read_csv(BBOX_DATA_DIR + OUTPUT_FILE)\n",
    "    score_names = list(df.columns)\n",
    "    completed_ids = df['ImageUniqueID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.df = dataset.df[~dataset.df['ImageUniqueID'].isin(completed_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65330/65330 [2:12:45<00:00,  8.20it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# create csv progress to save each step\n",
    "csv_progress = progress_log.CSVProgress(\n",
    "    filename=OUTPUT_FILE, path=BBOX_DATA_DIR)\n",
    "csv_progress.score_names = score_names\n",
    "\n",
    "# iterate images and find bboxes\n",
    "for i, (img, label) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    record_id = dataset.df['ImageUniqueID'].iloc[i]\n",
    "    if record_id not in completed_ids:\n",
    "        bbox = find_bbox(model, img, label, device=device)\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        vals = {\n",
    "            'ImageUniqueID': record_id,\n",
    "            'xmin': xmin,\n",
    "            'ymin': ymin,\n",
    "            'xmax': xmax,\n",
    "            'ymax': ymax}\n",
    "        csv_progress.log_epoch_scores(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
